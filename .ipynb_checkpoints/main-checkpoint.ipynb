{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "import tensorflow as tf\n",
    "from tkinter.ttk import *\n",
    "from PIL import ImageTk,Image\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dark spots Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Folder nodarkspots\n",
      "In Folder darkspots\n",
      "(610, 50, 50, 3)\n",
      "(610,)\n"
     ]
    }
   ],
   "source": [
    "features,target = [],[]\n",
    "\n",
    "for x in ['nodarkspots', 'darkspots']:\n",
    "    ImagesNamesList=os.listdir(\"images//train3\" + \"/\" + str(x))\n",
    "    for y in ImagesNamesList:\n",
    "        Imgarr=cv2.imread(r\"images//train3\" + \"/\" + str(x) + \"/\" + y)\n",
    "        try:\n",
    "            Imgarr=cv2.resize(Imgarr,(50,50))\n",
    "            features.append(Imgarr)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            if x==\"nodarkspots\":\n",
    "                target.append(0)\n",
    "            else:\n",
    "                target.append(1)\n",
    "    print(\"In Folder\", x)\n",
    "\n",
    "\n",
    "dark_spot_features = np.array(features)\n",
    "dark_spot_target = np.array(target)\n",
    "\n",
    "print(dark_spot_features.shape)\n",
    "print(dark_spot_target.shape)\n",
    "\n",
    "np.savez_compressed('datasets/dark_spot_data.npz', dark_spot_features, dark_spot_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puffy eyes Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Folder no puffy eyes\n",
      "In Folder puffy eyes\n",
      "(607, 50, 50, 3)\n",
      "(607,)\n"
     ]
    }
   ],
   "source": [
    "features,target = [],[]\n",
    "\n",
    "for x in ['no puffy eyes', 'puffy eyes']:\n",
    "    ImagesNamesList=os.listdir(\"images//train2\" + \"/\" + str(x))\n",
    "    for y in ImagesNamesList:\n",
    "        Imgarr=cv2.imread(r\"images//train2\" + \"/\" + str(x) + \"/\" + y)\n",
    "        try:\n",
    "            Imgarr=cv2.resize(Imgarr,(50,50))\n",
    "            features.append(Imgarr)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            if x==\"no puffy eyes\":\n",
    "                target.append(0)\n",
    "            else:\n",
    "                target.append(1)\n",
    "    print(\"In Folder\", x)\n",
    "\n",
    "\n",
    "eyes_features = np.array(features)\n",
    "eyes_target = np.array(target)\n",
    "\n",
    "print(eyes_features.shape)\n",
    "print(eyes_target.shape)\n",
    "\n",
    "np.savez_compressed('datasets/eyes_data.npz', eyes_features, eyes_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrinkles Data Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Folder NoWrinkles\n",
      "In Folder wrinkles\n",
      "(596, 50, 50, 3)\n",
      "(596,)\n"
     ]
    }
   ],
   "source": [
    "features,target = [],[]\n",
    "\n",
    "for x in ['NoWrinkles', 'wrinkles']:\n",
    "    ImagesNamesList=os.listdir(\"images//train1\" + \"/\" + str(x))\n",
    "    for y in ImagesNamesList:\n",
    "        Imgarr=cv2.imread(r\"images//train1\" + \"/\" + str(x) + \"/\" + y)\n",
    "        try:\n",
    "            Imgarr=cv2.resize(Imgarr,(50,50))\n",
    "            features.append(Imgarr)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            if x==\"NoWrinkles\":\n",
    "                target.append(0)\n",
    "            else:\n",
    "                target.append(1)\n",
    "    print(\"In Folder\", x)\n",
    "\n",
    "\n",
    "wrinkles_features = np.array(features)\n",
    "wrinkles_target = np.array(target)\n",
    "\n",
    "print(wrinkles_features.shape)\n",
    "print(wrinkles_target.shape)\n",
    "\n",
    "np.savez_compressed('datasets/wrinkles_data.npz', wrinkles_features, wrinkles_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image=image/255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Creation and  Compilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488, 50, 50, 3)\n",
      "(488,)\n",
      "(122, 50, 50, 3)\n",
      "(122,)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 27s 1s/step - loss: 20.4789 - accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 27s 1s/step - loss: 0.6771 - accuracy: 0.5594\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 28s 1s/step - loss: 0.6271 - accuracy: 0.6557\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5354 - accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5275 - accuracy: 0.7480\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.4997 - accuracy: 0.7910\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.4173 - accuracy: 0.8340\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.4596 - accuracy: 0.7910\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 27s 1s/step - loss: 0.3696 - accuracy: 0.8381\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2853 - accuracy: 0.9037\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2607 - accuracy: 0.8975\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2513 - accuracy: 0.9078\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2609 - accuracy: 0.8955\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2855 - accuracy: 0.8955\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2491 - accuracy: 0.9098\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2367 - accuracy: 0.9139\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.1681 - accuracy: 0.9283\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2219 - accuracy: 0.9242\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2169 - accuracy: 0.9139\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.1972 - accuracy: 0.9324\n",
      "(485, 50, 50, 3)\n",
      "(485,)\n",
      "(122, 50, 50, 3)\n",
      "(122,)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 15.0736 - accuracy: 0.5258\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5909 - accuracy: 0.6887\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.6139 - accuracy: 0.6722\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5862 - accuracy: 0.7175\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5046 - accuracy: 0.7608\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5731 - accuracy: 0.7402\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5376 - accuracy: 0.7320\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5163 - accuracy: 0.7649\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.4425 - accuracy: 0.7979\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.4465 - accuracy: 0.8144\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.4260 - accuracy: 0.8103\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.4328 - accuracy: 0.8227\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5622 - accuracy: 0.7835\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.5321 - accuracy: 0.7526\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.3865 - accuracy: 0.8206\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.4246 - accuracy: 0.8227\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.3797 - accuracy: 0.8412\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2810 - accuracy: 0.8784\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.3290 - accuracy: 0.8701\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 26s 1s/step - loss: 0.2265 - accuracy: 0.8969\n",
      "(476, 50, 50, 3)\n",
      "(476,)\n",
      "(120, 50, 50, 3)\n",
      "(120,)\n",
      "Epoch 1/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 13.7211 - accuracy: 0.5147\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.6921 - accuracy: 0.5693\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.6099 - accuracy: 0.6744\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.5075 - accuracy: 0.7563\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.4621 - accuracy: 0.7962\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.4042 - accuracy: 0.8214\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.3430 - accuracy: 0.8634\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.3286 - accuracy: 0.8697\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 26s 1s/step - loss: 0.2655 - accuracy: 0.8992\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.2858 - accuracy: 0.8761\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.3147 - accuracy: 0.8739\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.2916 - accuracy: 0.8908\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.2891 - accuracy: 0.8866\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.2512 - accuracy: 0.9055\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.2683 - accuracy: 0.8950\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 25s 1s/step - loss: 0.2404 - accuracy: 0.9139\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 24s 993ms/step - loss: 0.2137 - accuracy: 0.9307\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 24s 980ms/step - loss: 0.2414 - accuracy: 0.9181\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 20s 842ms/step - loss: 0.2476 - accuracy: 0.8992\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 19s 792ms/step - loss: 0.2580 - accuracy: 0.9013\n"
     ]
    }
   ],
   "source": [
    "for a in os.listdir('datasets/'):\n",
    "    data = np.load(r'datasets/'+str(a))\n",
    "    features , target = data['arr_0'],data['arr_1']\n",
    "\n",
    "    features_train,features_test,target_train,target_test=train_test_split(features,target,test_size=0.2)\n",
    "    print(features_train.shape)\n",
    "    print(target_train.shape)\n",
    "    print(features_test.shape)\n",
    "    print(target_test.shape)\n",
    "\n",
    "    dataGen=ImageDataGenerator(rotation_range=10,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2,shear_range=0.1)\n",
    "    batches=dataGen.flow(features_train,target_train,batch_size=20)\n",
    "    images,labels=next(batches)\n",
    "\n",
    "    target_train=to_categorical(target_train)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(100,(3,3),activation=\"relu\",input_shape=(50,50,3)))\n",
    "    model.add(Conv2D(200,(3,3),activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(100,(3,3),activation=\"relu\"))\n",
    "    model.add(Conv2D(100,(3,3),activation=\"relu\"))\n",
    "    model.add(Conv2D(100,(3,3),activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500,activation=\"relu\"))\n",
    "    model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(dataGen.flow(features_train,target_train,batch_size=20),epochs=20)\n",
    "\n",
    "    model_json=model.to_json()\n",
    "    with open(str(a[:6])+\".json\",\"w\") as abc:\n",
    "        abc.write(model_json)\n",
    "        abc.close\n",
    "    model.save_weights(\"models/\"+str(a[:6])+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model retriving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file=open(r\"models/dark_s.json\",\"r\")\n",
    "loaded_model_json=json_file.read()\n",
    "json_file.close()\n",
    "loaded_model=model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"models/dark_s.h5\")\n",
    "\n",
    "json_file=open(r\"models/eyes_d.json\",\"r\")\n",
    "loaded_model_json=json_file.read()\n",
    "json_file.close()\n",
    "loaded_model1=model_from_json(loaded_model_json)\n",
    "loaded_model1.load_weights(\"models/eyes_d.h5\")\n",
    "\n",
    "json_file=open(r\"models/wrinkl.json\",\"r\")\n",
    "loaded_model_json=json_file.read()\n",
    "json_file.close()\n",
    "loaded_model2=model_from_json(loaded_model_json)\n",
    "loaded_model2.load_weights(\"models/wrinkl.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dark spots', 'puffy eyes', 'wrinkles on face']\n"
     ]
    }
   ],
   "source": [
    "Imgarr0 = cv2.imread(r\"test_images/56.jpg\")\n",
    "Imgarr1=cv2.resize(Imgarr0,(50,50))\n",
    "Imgarr = Imgarr1.reshape(-1, 50, 50, 3)\n",
    "\n",
    "l = []\n",
    "\n",
    "result = loaded_model.predict(Imgarr)\n",
    "result = result[0]\n",
    "if result[0] >= result[1]:\n",
    "    l.append(\"dark spots\")\n",
    "else:\n",
    "    l.append(\"no dark spots\")\n",
    "\n",
    "result = loaded_model1.predict(Imgarr)\n",
    "result = result[0]\n",
    "if result[0] >= result[1]:\n",
    "    l.append(\"no puffy eyes\")\n",
    "else:\n",
    "    l.append(\"puffy eyes\")\n",
    "\n",
    "result = loaded_model2.predict(Imgarr)\n",
    "result = result[0]\n",
    "if result[0] >= result[1]:\n",
    "    l.append(\"no wrinkles on face\")\n",
    "else:\n",
    "    l.append(\"wrinkles on face\")\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootg = Tk()\n",
    "rootg.resizable(False,False)\n",
    "rootg.geometry('450x450')\n",
    "rootg.title('Facial Predictions')\n",
    "u2 = Image.open(\"images/images_2.jpg\")\n",
    "u2 = u2.resize((450,450),Image.ANTIALIAS)\n",
    "u2 = ImageTk.PhotoImage(u2)\n",
    "Label(rootg,image=u2).place(x=0, y=0, width=450, height=450)\n",
    "img = cv2.resize(Imgarr0, (300, 250))\n",
    "im = Image.fromarray(img)\n",
    "imgtk = ImageTk.PhotoImage(image=im) \n",
    "Label(rootg, image=imgtk).place(x=70,y=50)\n",
    "\n",
    "Label(rootg, text = \"Predictions are : \"+str(l)).place(x=50,y=350)\n",
    "rootg.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6a3e0889f8c2408124aa56f2e3ba9d6a1e0182abae64887b4920768fc621eb4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

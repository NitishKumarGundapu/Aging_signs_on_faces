{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "import tensorflow as tf\n",
    "from tkinter.ttk import *\n",
    "from PIL import ImageTk,Image\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dark spots Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Folder nodarkspots\n",
      "In Folder darkspots\n",
      "(610, 50, 50, 3)\n",
      "(610,)\n"
     ]
    }
   ],
   "source": [
    "features,target = [],[]\n",
    "\n",
    "for x in ['nodarkspots', 'darkspots']:\n",
    "    ImagesNamesList=os.listdir(\"images//train3\" + \"/\" + str(x))\n",
    "    for y in ImagesNamesList:\n",
    "        Imgarr=cv2.imread(r\"images//train3\" + \"/\" + str(x) + \"/\" + y)\n",
    "        try:\n",
    "            Imgarr=cv2.resize(Imgarr,(50,50))\n",
    "            features.append(Imgarr)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            if x==\"nodarkspots\":\n",
    "                target.append(0)\n",
    "            else:\n",
    "                target.append(1)\n",
    "    print(\"In Folder\", x)\n",
    "\n",
    "\n",
    "dark_spot_features = np.array(features)\n",
    "dark_spot_target = np.array(target)\n",
    "\n",
    "print(dark_spot_features.shape)\n",
    "print(dark_spot_target.shape)\n",
    "\n",
    "np.savez_compressed('datasets/dark_spot_data.npz', dark_spot_features, dark_spot_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puffy eyes Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Folder no puffy eyes\n",
      "In Folder puffy eyes\n",
      "(607, 50, 50, 3)\n",
      "(607,)\n"
     ]
    }
   ],
   "source": [
    "features,target = [],[]\n",
    "\n",
    "for x in ['no puffy eyes', 'puffy eyes']:\n",
    "    ImagesNamesList=os.listdir(\"images//train2\" + \"/\" + str(x))\n",
    "    for y in ImagesNamesList:\n",
    "        Imgarr=cv2.imread(r\"images//train2\" + \"/\" + str(x) + \"/\" + y)\n",
    "        try:\n",
    "            Imgarr=cv2.resize(Imgarr,(50,50))\n",
    "            features.append(Imgarr)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            if x==\"no puffy eyes\":\n",
    "                target.append(0)\n",
    "            else:\n",
    "                target.append(1)\n",
    "    print(\"In Folder\", x)\n",
    "\n",
    "\n",
    "eyes_features = np.array(features)\n",
    "eyes_target = np.array(target)\n",
    "\n",
    "print(eyes_features.shape)\n",
    "print(eyes_target.shape)\n",
    "\n",
    "np.savez_compressed('datasets/eyes_data.npz', eyes_features, eyes_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrinkles Data Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Folder NoWrinkles\n",
      "In Folder wrinkles\n",
      "(596, 50, 50, 3)\n",
      "(596,)\n"
     ]
    }
   ],
   "source": [
    "features,target = [],[]\n",
    "\n",
    "for x in ['NoWrinkles', 'wrinkles']:\n",
    "    ImagesNamesList=os.listdir(\"images//train1\" + \"/\" + str(x))\n",
    "    for y in ImagesNamesList:\n",
    "        Imgarr=cv2.imread(r\"images//train1\" + \"/\" + str(x) + \"/\" + y)\n",
    "        try:\n",
    "            Imgarr=cv2.resize(Imgarr,(50,50))\n",
    "            features.append(Imgarr)\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            if x==\"NoWrinkles\":\n",
    "                target.append(0)\n",
    "            else:\n",
    "                target.append(1)\n",
    "    print(\"In Folder\", x)\n",
    "\n",
    "\n",
    "wrinkles_features = np.array(features)\n",
    "wrinkles_target = np.array(target)\n",
    "\n",
    "print(wrinkles_features.shape)\n",
    "print(wrinkles_target.shape)\n",
    "\n",
    "np.savez_compressed('datasets/wrinkles_data.npz', wrinkles_features, wrinkles_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image=image/255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Creation and  Compilation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(488, 50, 50, 3)\n",
      "(488,)\n",
      "(122, 50, 50, 3)\n",
      "(122,)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 20s 779ms/step - loss: 12.1152 - accuracy: 0.4836\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 20s 805ms/step - loss: 0.6909 - accuracy: 0.5512\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 23s 929ms/step - loss: 0.6380 - accuracy: 0.6148\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 23s 929ms/step - loss: 0.6335 - accuracy: 0.7111\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 22s 882ms/step - loss: 0.5513 - accuracy: 0.7152\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 21s 820ms/step - loss: 0.5447 - accuracy: 0.7234\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 20s 796ms/step - loss: 0.4431 - accuracy: 0.8033\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 20s 811ms/step - loss: 0.3970 - accuracy: 0.8094\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 20s 795ms/step - loss: 0.3347 - accuracy: 0.8791\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 20s 793ms/step - loss: 0.2835 - accuracy: 0.9037\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 20s 796ms/step - loss: 0.2399 - accuracy: 0.8996\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 20s 799ms/step - loss: 0.2019 - accuracy: 0.9283\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 20s 801ms/step - loss: 0.2379 - accuracy: 0.9078\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 20s 794ms/step - loss: 0.2752 - accuracy: 0.8873\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 20s 794ms/step - loss: 0.2057 - accuracy: 0.9262\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 20s 798ms/step - loss: 0.2522 - accuracy: 0.9098\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 20s 812ms/step - loss: 0.1441 - accuracy: 0.9467\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 21s 823ms/step - loss: 0.1576 - accuracy: 0.9385\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 20s 801ms/step - loss: 0.1527 - accuracy: 0.9406\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 20s 801ms/step - loss: 0.1890 - accuracy: 0.9283\n",
      "(485, 50, 50, 3)\n",
      "(485,)\n",
      "(122, 50, 50, 3)\n",
      "(122,)\n",
      "Epoch 1/20\n",
      "25/25 [==============================] - 21s 798ms/step - loss: 13.7513 - accuracy: 0.5361\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 0.6328 - accuracy: 0.6206\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 0.6755 - accuracy: 0.6082\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 20s 794ms/step - loss: 0.5396 - accuracy: 0.6990\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 20s 796ms/step - loss: 0.4759 - accuracy: 0.7608\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 21s 817ms/step - loss: 0.4651 - accuracy: 0.7938\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 20s 792ms/step - loss: 0.4693 - accuracy: 0.7732\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 0.4194 - accuracy: 0.8186\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 20s 796ms/step - loss: 0.3801 - accuracy: 0.8227\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 0.3675 - accuracy: 0.8495\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 20s 794ms/step - loss: 0.3191 - accuracy: 0.8660\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 20s 800ms/step - loss: 0.2849 - accuracy: 0.8845\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 20s 790ms/step - loss: 0.3274 - accuracy: 0.8577\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 0.2997 - accuracy: 0.8866\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 20s 812ms/step - loss: 0.3178 - accuracy: 0.8639\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 20s 792ms/step - loss: 0.3271 - accuracy: 0.8763\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 20s 794ms/step - loss: 0.3224 - accuracy: 0.8474\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 20s 792ms/step - loss: 0.2784 - accuracy: 0.8722\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 20s 793ms/step - loss: 0.2836 - accuracy: 0.8804\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 20s 794ms/step - loss: 0.2875 - accuracy: 0.8928\n",
      "(476, 50, 50, 3)\n",
      "(476,)\n",
      "(120, 50, 50, 3)\n",
      "(120,)\n",
      "Epoch 1/20\n",
      "24/24 [==============================] - 21s 819ms/step - loss: 13.5808 - accuracy: 0.5462\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 20s 810ms/step - loss: 0.6995 - accuracy: 0.5651\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 20s 813ms/step - loss: 0.7700 - accuracy: 0.6050\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 20s 835ms/step - loss: 0.6756 - accuracy: 0.5945\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 20s 814ms/step - loss: 0.5934 - accuracy: 0.6933\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 20s 811ms/step - loss: 0.5630 - accuracy: 0.7353\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 20s 812ms/step - loss: 0.4460 - accuracy: 0.8025\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 20s 818ms/step - loss: 0.3580 - accuracy: 0.8529\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 20s 811ms/step - loss: 0.2851 - accuracy: 0.8718\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 20s 809ms/step - loss: 0.2725 - accuracy: 0.9013\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 20s 815ms/step - loss: 0.3550 - accuracy: 0.8445\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 20s 814ms/step - loss: 0.3691 - accuracy: 0.8613\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 20s 812ms/step - loss: 0.3033 - accuracy: 0.8697\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 20s 828ms/step - loss: 0.2406 - accuracy: 0.8971\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 20s 810ms/step - loss: 0.2423 - accuracy: 0.8971\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 20s 814ms/step - loss: 0.2789 - accuracy: 0.8866\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 20s 812ms/step - loss: 0.2523 - accuracy: 0.9055\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 20s 808ms/step - loss: 0.2257 - accuracy: 0.9181\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 19s 808ms/step - loss: 0.1942 - accuracy: 0.9307\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 20s 806ms/step - loss: 0.2534 - accuracy: 0.9076\n"
     ]
    }
   ],
   "source": [
    "for a in os.listdir('datasets/'):\n",
    "    data = np.load(r'datasets/'+str(a))\n",
    "    features , target = data['arr_0'],data['arr_1']\n",
    "\n",
    "    features_train,features_test,target_train,target_test=train_test_split(features,target,test_size=0.2)\n",
    "    print(features_train.shape)\n",
    "    print(target_train.shape)\n",
    "    print(features_test.shape)\n",
    "    print(target_test.shape)\n",
    "\n",
    "    dataGen=ImageDataGenerator(rotation_range=10,width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2,shear_range=0.1)\n",
    "    batches=dataGen.flow(features_train,target_train,batch_size=20)\n",
    "    images,labels=next(batches)\n",
    "\n",
    "    target_train=to_categorical(target_train)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(100,(3,3),activation=\"relu\",input_shape=(50,50,3)))\n",
    "    model.add(Conv2D(200,(3,3),activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(100,(3,3),activation=\"relu\"))\n",
    "    model.add(Conv2D(100,(3,3),activation=\"relu\"))\n",
    "    model.add(Conv2D(100,(3,3),activation=\"relu\"))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500,activation=\"relu\"))\n",
    "    model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(dataGen.flow(features_train,target_train,batch_size=20),epochs=20)\n",
    "\n",
    "    model_json=model.to_json()\n",
    "    with open(str(a[:6])+\".json\",\"w\") as abc:\n",
    "        abc.write(model_json)\n",
    "        abc.close\n",
    "    model.save_weights(\"models/\"+str(a[:6])+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model retriving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file=open(r\"models/dark_s.json\",\"r\")\n",
    "loaded_model_json=json_file.read()\n",
    "json_file.close()\n",
    "loaded_model=model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"models/dark_s.h5\")\n",
    "\n",
    "json_file=open(r\"models/eyes_d.json\",\"r\")\n",
    "loaded_model_json=json_file.read()\n",
    "json_file.close()\n",
    "loaded_model1=model_from_json(loaded_model_json)\n",
    "loaded_model1.load_weights(\"models/eyes_d.h5\")\n",
    "\n",
    "json_file=open(r\"models/wrinkl.json\",\"r\")\n",
    "loaded_model_json=json_file.read()\n",
    "json_file.close()\n",
    "loaded_model2=model_from_json(loaded_model_json)\n",
    "loaded_model2.load_weights(\"models/wrinkl.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000286441D8940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028644359A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "['no dark spots', 'puffy eyes', 'wrinkles on face']\n"
     ]
    }
   ],
   "source": [
    "Imgarr0 = cv2.imread(r\"test_images/42.jpg\")\n",
    "Imgarr1=cv2.resize(Imgarr0,(50,50))\n",
    "Imgarr = Imgarr1.reshape(-1, 50, 50, 3)\n",
    "\n",
    "l = []\n",
    "\n",
    "result = loaded_model.predict(Imgarr)\n",
    "result = result[0]\n",
    "if result[0] >= result[1]:\n",
    "    l.append(\"dark spots\")\n",
    "else:\n",
    "    l.append(\"no dark spots\")\n",
    "\n",
    "result = loaded_model1.predict(Imgarr)\n",
    "result = result[0]\n",
    "if result[0] >= result[1]:\n",
    "    l.append(\"no puffy eyes\")\n",
    "else:\n",
    "    l.append(\"puffy eyes\")\n",
    "\n",
    "result = loaded_model2.predict(Imgarr)\n",
    "result = result[0]\n",
    "if result[0] >= result[1]:\n",
    "    l.append(\"no wrinkles on face\")\n",
    "else:\n",
    "    l.append(\"wrinkles on face\")\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootg = Tk()\n",
    "rootg.resizable(False,False)\n",
    "rootg.geometry('450x450')\n",
    "rootg.title('Facial Predictions')\n",
    "u2 = Image.open(\"images/images_2.jpg\")\n",
    "u2 = u2.resize((450,450),Image.ANTIALIAS)\n",
    "u2 = ImageTk.PhotoImage(u2)\n",
    "Label(rootg,image=u2).place(x=0, y=0, width=450, height=450)\n",
    "img = cv2.resize(Imgarr0, (300, 250))\n",
    "im = Image.fromarray(img)\n",
    "imgtk = ImageTk.PhotoImage(image=im) \n",
    "Label(rootg, image=imgtk).place(x=70,y=50)\n",
    "\n",
    "Label(rootg, text = \"Predictions are : \"+str(l)).place(x=50,y=350)\n",
    "rootg.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6a3e0889f8c2408124aa56f2e3ba9d6a1e0182abae64887b4920768fc621eb4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
